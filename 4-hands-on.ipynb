{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Грамматики составляющих\n",
    "NLTK умеет читать грамматику из строчки и из файла. Попробуем сначала строчки. Запишем пример грамматики и превратим в список, чтобы потом было удобнее добавлять правила:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "rules = \"\"\"\n",
    "    S -> NP VP\n",
    "    NP -> Det ADJ N | Det N | NN\n",
    "    VP -> V NP | VP PP | V\n",
    "    Det -> 'a'\n",
    "    ADJ -> 'tasty' | ADV ADJ\n",
    "    ADV -> 'very'\n",
    "    N -> 'fish' | 'fork' | 'dog' | 'boy'\n",
    "    NN -> 'Mary' | 'John'\n",
    "    V -> 'eats'\n",
    "    PP -> P NP |\n",
    "    P -> 'with'\n",
    "\"\"\".split('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь склеим список обратно в строчку и превратим в грамматику NLTK.grammar.CFG:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "grammar = nltk.CFG.fromstring('\\n'.join(rules))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Можно посмотреть, что это за объект\n",
    "?nltk.CFG\n",
    "#help(grammar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь используем эту грамматику для разбора с помощью парсера Эрли (да, он есть в NLTK):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp = nltk.EarleyChartParser(grammar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Поищем, как теперь разобрать предложение парсером:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on EarleyChartParser in module nltk.parse.earleychart object:\n",
      "\n",
      "class EarleyChartParser(IncrementalChartParser)\n",
      " |  EarleyChartParser(grammar, **parser_args)\n",
      " |  \n",
      " |  An *incremental* chart parser implementing Jay Earley's\n",
      " |  parsing algorithm:\n",
      " |  \n",
      " |  | For each index end in [0, 1, ..., N]:\n",
      " |  |   For each edge such that edge.end = end:\n",
      " |  |     If edge is incomplete and edge.next is not a part of speech:\n",
      " |  |       Apply PredictorRule to edge\n",
      " |  |     If edge is incomplete and edge.next is a part of speech:\n",
      " |  |       Apply ScannerRule to edge\n",
      " |  |     If edge is complete:\n",
      " |  |       Apply CompleterRule to edge\n",
      " |  | Return any complete parses in the chart\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      EarleyChartParser\n",
      " |      IncrementalChartParser\n",
      " |      nltk.parse.chart.ChartParser\n",
      " |      nltk.parse.api.ParserI\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, grammar, **parser_args)\n",
      " |      Create a new Earley chart parser, that uses ``grammar`` to\n",
      " |      parse texts.\n",
      " |      \n",
      " |      :type grammar: CFG\n",
      " |      :param grammar: The grammar used to parse texts.\n",
      " |      :type trace: int\n",
      " |      :param trace: The level of tracing that should be used when\n",
      " |          parsing a text.  ``0`` will generate no tracing output;\n",
      " |          and higher numbers will produce more verbose tracing\n",
      " |          output.\n",
      " |      :type trace_chart_width: int\n",
      " |      :param trace_chart_width: The default total width reserved for\n",
      " |          the chart in trace output.  The remainder of each line will\n",
      " |          be used to display edges.\n",
      " |      :param chart_class: The class that should be used to create\n",
      " |          the charts used by this parser.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from IncrementalChartParser:\n",
      " |  \n",
      " |  chart_parse(self, tokens, trace=None)\n",
      " |      Return the final parse ``Chart`` from which all possible\n",
      " |      parse trees can be extracted.\n",
      " |      \n",
      " |      :param tokens: The sentence to be parsed\n",
      " |      :type tokens: list(str)\n",
      " |      :rtype: Chart\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from nltk.parse.chart.ChartParser:\n",
      " |  \n",
      " |  grammar(self)\n",
      " |      :return: The grammar used by this parser.\n",
      " |  \n",
      " |  parse(self, tokens, tree_class=<class 'nltk.tree.Tree'>)\n",
      " |      :return: An iterator that generates parse trees for the sentence.\n",
      " |      When possible this list is sorted from most likely to least likely.\n",
      " |      \n",
      " |      :param sent: The sentence to be parsed\n",
      " |      :type sent: list(str)\n",
      " |      :rtype: iter(Tree)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from nltk.parse.api.ParserI:\n",
      " |  \n",
      " |  parse_all(self, sent, *args, **kwargs)\n",
      " |      :rtype: list(Tree)\n",
      " |  \n",
      " |  parse_one(self, sent, *args, **kwargs)\n",
      " |      :rtype: Tree or None\n",
      " |  \n",
      " |  parse_sents(self, sents, *args, **kwargs)\n",
      " |      Apply ``self.parse()`` to each element of ``sents``.\n",
      " |      :rtype: iter(iter(Tree))\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from nltk.parse.api.ParserI:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(cp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Метод `parse` возвращает итератор. Чтобы каждый раз не писать цикл, давайте заведём функцию, которая будет разбивать предложение на токены, проходить по всем разборам и печатать их:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_parses(parser, sentence):\n",
    "    ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_parses(cp, \"Mary eats a fish\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вернемся к описанию EarleyChartParser и найдём, как включить отладочный вывод -- чтобы посмотреть на шаги разбора."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##cp_verbose = nltk.EarleyChartParser(grammar)\n",
    "print_parses(cp_verbose, \"Mary eats a fish\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Можно больше отладочного вывода!\n",
    "##very_verbose_cp = nltk.EarleyChartParser(grammar)\n",
    "print_parses(very_verbose_cp, \"Mary eats a very tasty fish\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разборы можно не только печатать в формате составляющих со скобками, но и рисовать:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Положим все разборы в список, чтобы получать к ним доступ по индексу\n",
    "p = list(cp.parse(\"Mary eats a fish\".split()))\n",
    "# Посмотрим, сколько разборов получилось\n",
    "len(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверим, почему получилось два разбора -- разве входное предложение неоднозначно?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разберём классический пример неоднозначности: *One morning I shot an elephant in my pajamas* (https://www.kinopoisk.ru/film/1749/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ambiguous_sentence = 'One morning I shot an elephant in my pajamas'\n",
    "##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Что пошло не так? Давайте это исправим!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сначала будет полезно посмотреть на правила, которые уже есть в грамматике\n",
    "grammar.productions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "add_rules = \"\"\"\n",
    "\"\"\".split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Добавим правила и заведем новую грамматику\n",
    "##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Попробуем разобрать. Если что-то ломается, полезно включать отладочный вывод\n",
    "cp = nltk.EarleyChartParser(grammar)\n",
    "print_parses(cp, ambiguous_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Грамматики зависимостей\n",
    "Можно использовать то же предложение, поскольку неоднозначность проявляется и в представлении зависимостей.\n",
    "В NLTK можно примерно одинаково работать с CFG и зависимостями (`DependencyGrammar`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dep_rules = \"\"\"\n",
    "... 'shot' -> 'I' | 'elephant' | 'in' | 'morning'\n",
    "... 'morning' -> 'One'\n",
    "... 'elephant' -> 'an' | 'in'\n",
    "... 'in' -> 'pajamas'\n",
    "... 'pajamas' -> 'my'\n",
    "... \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dep_grammar = nltk.DependencyGrammar.fromstring(dep_rules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdp = nltk.ProjectiveDependencyParser(dep_grammar)\n",
    "sent = 'One morning I shot an elephant in my pajamas'\n",
    "print_parses(pdp, sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parses = list(pdp.parse(sent.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parses[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parses[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Встроенные грамматики NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.data.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = []\n",
    "with open(\"%s/grammars/large_grammars/atis_sentences.txt\" % nltk.data.path[0], encoding=\"utf-8\") as f:\n",
    "    ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "atis_parser = nltk.load_parser('grammars/large_grammars/atis.cfg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Посмотрим на предложения\n",
    "sentences[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_parses(atis_parser, sentences[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parses = list(atis_parser.parse(sentences[0]))\n",
    "parses[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
