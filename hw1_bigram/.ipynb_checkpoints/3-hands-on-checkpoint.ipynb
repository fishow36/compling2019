{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# загрузим привычный корпус\n",
    "corpus = nltk.corpus.conll2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Confidence', 'in', 'the', 'pound', 'is']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# возьмем список (неразмеченных) слов и предложений из корпуса\n",
    "words = corpus.words()\n",
    "sents = corpus.sents()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NLTK умеет считать частоты по корпусу и даже извлекать триграммы из списков слов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of unigram FreqDist = 21589\n",
      "Length of trigrams FreqDist by words = 212933\n",
      "Length of trigrams FreqDist by sents = 196878\n"
     ]
    }
   ],
   "source": [
    "from nltk.probability import FreqDist\n",
    "from nltk import trigrams\n",
    "\n",
    "unigram_fd = FreqDist()\n",
    "words_fd = FreqDist()\n",
    "sents_fd = FreqDist()\n",
    "\n",
    "unigram_fd.update(words)\n",
    "words_fd.update(trigrams(words))\n",
    "for sent in sents:\n",
    "    sents_fd.update(trigrams(sent))\n",
    "\n",
    "print('Length of unigram FreqDist = {}'.format(len(unigram_fd)))\n",
    "print('Length of trigrams FreqDist by words = {}'.format(len(words_fd)))\n",
    "print('Length of trigrams FreqDist by sents = {}'.format(len(sents_fd)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Можно почитать, что представляет собой объект FreqDist\n",
    "?words_fd\n",
    "# или: help(words_fd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем вывести самые частые 10 триграмм:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('million', ',', 'or'), 256),\n",
       " (('a', 'share', ','), 240),\n",
       " ((',', \"''\", 'says'), 195),\n",
       " (('cents', 'a', 'share'), 161),\n",
       " ((',', \"''\", 'said'), 138),\n",
       " (('%', 'to', '$'), 134),\n",
       " ((',', 'or', '$'), 125),\n",
       " (('the', 'company', \"'s\"), 114),\n",
       " ((',', \"''\", 'he'), 109),\n",
       " (('a', 'year', 'earlier'), 91)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sents_fd.most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Всевозможные улучшения для языковых моделей в NLTK тоже есть, и тоже не очень удобные:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('who', 'are', 'not') 2.3036219848467746e-06 0.009112681815526607\n",
      "('who', 'is', 'the') 4.607243969693549e-06 0.011904761904761904\n",
      "('I', 'love', 'you') 2.3036219848467746e-06 0.0\n",
      "('in', 'San', 'Francisco') 4.146519572724194e-05 0.7386363636363636\n",
      "('to', 'San', 'Diego') 2.3036219848467746e-06 0.012499999999999999\n"
     ]
    }
   ],
   "source": [
    "from nltk.probability import LaplaceProbDist, KneserNeyProbDist\n",
    "\n",
    "eval_trigrams = [\n",
    "    ('who', 'are', 'not'),\n",
    "    ('who', 'is', 'the'),\n",
    "    ('I', 'love', 'you'),\n",
    "    ('in', 'San', 'Francisco'),\n",
    "    ('to', 'San', 'Diego'),\n",
    "]\n",
    "\n",
    "laplace = LaplaceProbDist(sents_fd)\n",
    "kn = KneserNeyProbDist(sents_fd)\n",
    "for t in eval_trigrams:\n",
    "    print(t, laplace.prob(t), kn.prob(t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как проверить, какие из триграмм были в частотном списке?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sents_fd[('who', 'are', 'not')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Генерация случайных текстов (character-based)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для того, чтобы сгенерировать случайный текст нужно запастись двумя вещами:\n",
    "\n",
    "1. Обучающий корпус.\n",
    "2. Языковая модель."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Читаем обучающий корпус из input.txt\n",
    "#with open('input.txt', encoding = 'utf-8') as f:\n",
    "    \n",
    "   # corpus = f.read()\n",
    "print(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.Как обычно - реализуем класс для языковой модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter, defaultdict\n",
    "\n",
    "class CharLM:\n",
    "    def __init__(self, data, order=4):\n",
    "        self.order = order\n",
    "        self.ngrams = defaultdict(Counter)\n",
    "        pad = '~' * order  # специальный символ для начала предложения (для первого символа будет ~~)\n",
    "        data = pad + data\n",
    "        # Для каждой n-граммы из символов посчитаем символы, которые идут перед ней\n",
    "        # Например, если порядок модели 2, а корпус выглядит так 'abcbcb':\n",
    "        # self.ngrams['~~']['a'] == 1\n",
    "        # self.ngrams['~a']['b'] == 1\n",
    "        # self.ngrams['ab']['c'] == 1\n",
    "        # self.ngrams['bc']['b'] == 2\n",
    "        # self.ngrams['cb']['c'] == 1\n",
    "        for i in range(len(data) - order):\n",
    "            history, char = data[i:i+order], data[i+order]\n",
    "            self.ngrams[history][char] +=1\n",
    "        self.lm = {history: self.normalize(chars) for history, chars in self.ngrams.items()}\n",
    "    \n",
    "    def normalize(self, counter):\n",
    "        # Всё как обычно - превращаем частоты в вероятности\n",
    "        # сделаем только в одну строчку - more pythonic ;)\n",
    "        sum_ = sum(counter.values())\n",
    "        return [(char, count / sum_) for char, count in counter.items()]\n",
    "    \n",
    "    def __getitem__(self, history):\n",
    "        return self.lm[history]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучаем модель:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = CharLM(corpus, order=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим, что получилось:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('g', 0.31507541149193086),\n",
       " ('k', 0.04090815178714906),\n",
       " ('v', 0.003259796607056771),\n",
       " (' ', 0.2515093776543238),\n",
       " ('s', 0.040449025504465004),\n",
       " ('e', 0.07871720116618076),\n",
       " ('t', 0.04788687128394665),\n",
       " ('d', 0.06202796079061546),\n",
       " (';', 0.005279952250866601),\n",
       " ('\\n', 0.010651729758270011),\n",
       " ('c', 0.03606436950483231),\n",
       " ('i', 0.012488234889006222),\n",
       " ('o', 0.0022267624710176535),\n",
       " (\"'\", 0.008884093569936411),\n",
       " (',', 0.0202015564380983),\n",
       " ('f', 0.007896972062165698),\n",
       " ('u', 0.0036500539473382156),\n",
       " ('.', 0.011799545464980143),\n",
       " ('n', 0.006657331098918758),\n",
       " ('h', 0.0016758109317967908),\n",
       " ('l', 0.0016758109317967908),\n",
       " ('j', 0.0017446798741993985),\n",
       " ('a', 0.009985996648378136),\n",
       " ('y', 0.0011478157067101307),\n",
       " ('q', 0.0009182525653681045),\n",
       " ('-', 0.001836505130736209),\n",
       " ('!', 0.0030531897798489476),\n",
       " ('?', 0.003145015036385758),\n",
       " (':', 0.00711645738160281),\n",
       " ('m', 0.0008952962512339019),\n",
       " ('w', 0.0006657331098918757),\n",
       " ('b', 0.0003443447120130392),\n",
       " ('r', 4.591262826840523e-05),\n",
       " ('x', 9.182525653681045e-05),\n",
       " ('p', 2.2956314134202613e-05)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm['in']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(' ', 0.8530393325387365),\n",
       " ('t', 0.025387365911799763),\n",
       " ('f', 0.06930870083432658),\n",
       " (',', 0.004886769964243146),\n",
       " (\"'\", 0.0005363528009535161),\n",
       " ('e', 0.004350417163289631),\n",
       " ('\\n', 0.02234803337306317),\n",
       " ('-', 0.0004171632896305125),\n",
       " ('a', 0.0017282479141835518),\n",
       " (';', 0.0017878426698450535),\n",
       " ('o', 0.0012514898688915374),\n",
       " (':', 0.0010727056019070322),\n",
       " ('u', 0.0015494636471990466),\n",
       " ('.', 0.005184743742550656),\n",
       " ('!', 0.0004171632896305125),\n",
       " ('s', 0.0012514898688915374),\n",
       " ('i', 0.003933253873659118),\n",
       " ('?', 0.0015494636471990466)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm['of']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А теперь напишем функцию для генерации случайных текстов!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import random\n",
    "\n",
    "def generate_letter(lm, history):\n",
    "    history = history[-lm.order:]\n",
    "    # По предыдущим символам будем генерировать следующий с учётом вероятностей\n",
    "    dist = lm[history]\n",
    "    x = random()\n",
    "    for char, prob in dist:\n",
    "        x = x - prob\n",
    "        if x <= 0:\n",
    "            return char\n",
    "        \n",
    "def generate_text(lm, n_letters=1000):\n",
    "    history = '~' * lm.order\n",
    "    out = []\n",
    "    # Генерируем текст длины n_letters\n",
    "    for i in range(n_letters):\n",
    "        # на каждом шаге генерируем новый символ\n",
    "        c = generate_letter(lm, history)\n",
    "        # обновляем историю и результат\n",
    "        history = history[-lm.order:] + c\n",
    "        out.append(c)\n",
    "    return ''.join(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем генерировать тексты разной длины с помощью моделей разного порядка -- 2...10?\n",
    "\n",
    "Какой результат более разнообразный? Какой более связный?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Firry mocke nus on, clem nablorell theyedly.\n",
      "\n",
      "Ford wous fiechat unext.\n",
      "And:\n",
      "Old tourse but suctusand.\n",
      "\n",
      "Fourse sher'd and, Isbal,\n",
      "We manced kin aft alit.\n",
      "\n",
      "PEY:\n",
      "Is rich,\n",
      "Helooly be fort, fly kill well yeact the dron to-majea, Kinhape:\n",
      "Whiscit. To this; ineseenall\n",
      "I died ormseek youbst an my faing that of the tus; in nay\n",
      "I hapkinne, Thou waseetery ban, graw that day, this sters to hat e's fropand the slike a mee warrandoestrughty's now my and yourpea st old! Tell you ne,--\n",
      "Ande,\n",
      "Whe to the kingbrous all moughtfull to son do we pre seeplesse rall. But yous?\n",
      "\n",
      "FALIAND:\n",
      "Upons a gencell, up; and th\n",
      "Mas oftea, riam, I he preadis fuld withe up to Iscom ifencee, bot. Cand to he fice.\n",
      "\n",
      "Can of manto as I wifthe thin hus;\n",
      "EDWARETH:\n",
      "Thee sand.\n",
      "BROIN:\n",
      "Have, I bant.\n",
      "LAUDE:\n",
      "He\n",
      "sit of st as withad, the groul,\n",
      "To lory arguiscomap hemptearcunce wortiring the.\n",
      "\n",
      "DRONICK:\n",
      "Yessize is I ass-mad tret nouds: hisday frialoads, thave I it intly hat\n",
      "we ne;\n",
      "hy thich def\n",
      "A me;\n",
      "To diesandend inspowit.\n",
      "\n",
      "Fir thanto this.\n"
     ]
    }
   ],
   "source": [
    "print(generate_text(lm, 1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Citizen:\n",
      "Go fetch a look so strange\n",
      "queen's are not with you.\n",
      "\n",
      "First Clown:\n",
      "A pestilent constitution, so help me! how long farewell.\n",
      "\n",
      "VIOLA:\n",
      "Nay, rather chose\n",
      "To cross me from home.\n",
      "Here did I hear\n",
      "Macduff is missing.\n",
      "\n",
      "LADY ANNE:\n",
      "Why, that Armado.\n",
      "\n",
      "BIRON:\n",
      "And sent her?\n",
      "\n",
      "ARIEL:\n",
      "I prithee now: how far forth to\n",
      "sleep. Look, here\n",
      "is a better by the\n",
      "nose for wearing, quarrel sir! no, sir: we have\n",
      "The prenzie Angelo, and we'll come they of\n",
      "these profound her to,\n",
      "And never did these things indeed is chronicle,\n",
      "That struck her\n",
      "into amaze your fights:\n",
      "Give fire:\n",
      "The throng who\n",
      "should quench'd this with Juliet.\n",
      "\n",
      "ROMEO:\n",
      "My dear son\n",
      "Shall lose for my liege?\n",
      "\n",
      "KING JOHN:\n",
      "Acknowledge, where the ground, I warrant us;\n",
      "she for the white o' the stern ungentle bosom, I from me my state;\n",
      "And I will not out what says he comes the spirit of my consent to the purpose only that cons state and made that drew this ground,\n",
      "Demanding on that pilgrimage.\n",
      "\n",
      "JOHN OF GAUNT:\n",
      "I have an excellent.\n",
      "Their ships already delivered within this rich reprisal is so richly fraughtage, sir,\n",
      "To let an arrogance with thee: provide,\n",
      "Your dicipline in war,\n",
      "Be blind itself in post\n",
      "To sacred which even her physic.\n",
      "\n",
      "DUKE VINCENTIO:\n",
      "Where, by me,\n",
      "Pleading and present reconcile\n",
      "This likewise enriches him to these,\n",
      "To stop the cedar's top,\n",
      "And not all the rest shoot.\n",
      "\n",
      "SHALLOW:\n",
      "\n",
      "SHALLOW:\n",
      "She never amend.\n",
      "\n",
      "MARK ANTONY:\n",
      "Unarm, Eros; and my fellow!\n",
      "\n",
      "SHALLOW:\n",
      "By thee, see that you with an eye of one nature and of hell\n",
      "Go, hie thee, Regan.\n",
      "Edmund, enkindled, and yet not seal to such perilous time.\n",
      "Well said!\n",
      "thou lovest,\n",
      "Shall we fight.\n",
      "The raging broils,\n",
      "Combat willingly these two\n",
      "may run mad indeed.\n",
      "\n",
      "BRABANTIO:\n",
      "How farest thou, Charles, it should he were Cassius,\n",
      "That I had suborn'd the watch.\n",
      "\n",
      "DOGBERRY:\n",
      "Moreover, hast thou keep'st command: unequal odds,\n",
      "And feast together.\n",
      "Antipholus,\n",
      "During all; whose conceptions on!\n",
      "\n",
      "AENEAS:\n",
      "Hail, King Henry gives way to-morrow that the tune.\n",
      "\n",
      "ROSALIND:\n",
      "Do you married. O, most truly\n"
     ]
    }
   ],
   "source": [
    "lm8 = CharLM(corpus, order=8)\n",
    "print(generate_text(lm8, 2000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
